{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8ykWIdNKghm",
        "outputId": "04d7736d-fdeb-4914-c1d7-5e58c039df70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting model.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile model.py\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import GRU, Dropout, Dense, LSTM, SimpleRNN\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import datetime\n",
        "import yfinance as yf\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from currency import get_prediction\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import warnings\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "def predict():\n",
        "    base = st.sidebar.selectbox('Choose currency pair',\n",
        "                                ['EUR-USD', 'GBP-USD', 'USD-CAD'])\n",
        "    model = st.sidebar.selectbox('Choose model',\n",
        "                                ['RNN', 'LSTM', 'GRU', 'MLP', 'ANN'])\n",
        "\n",
        "    input_open_price = st.sidebar.number_input('Enter Open Price')\n",
        "    input_high_price = st.sidebar.number_input('Enter High Price')\n",
        "    input_low_price = st.sidebar.number_input('Enter Low Price')\n",
        "    input_close_price = st.sidebar.number_input('Enter Close Price')\n",
        "\n",
        "    input_price = np.array([input_open_price, input_high_price,\n",
        "                            input_low_price, input_close_price, 0])\n",
        "\n",
        "    input_price = input_price.reshape(1, -1)\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    input_price = scaler.fit_transform(input_price)\n",
        "\n",
        "    if '-' in base:\n",
        "      base = base.replace('-','')\n",
        "\n",
        "    symbol= f'{base}=X'\n",
        "    if st.sidebar.button('Accept'):\n",
        "        data = download_data(symbol)\n",
        "        st.sidebar.success('Data Downloaded!')\n",
        "        if 'RNN' in model:\n",
        "          RNN_model(data, symbol, input_price)\n",
        "        if 'LSTM' in model:\n",
        "          LSTM_model(data, symbol, input_price)\n",
        "        if 'GRU' in model:\n",
        "          GRU_model(data, symbol, input_price)\n",
        "        if 'MLP' in model:\n",
        "          MLP_model(data, symbol, input_price)\n",
        "        if 'ANN' in model:\n",
        "          ANN_model(data, symbol, input_price)\n",
        "\n",
        "@st.cache_resource\n",
        "def download_data(symbol):\n",
        "    df = yf.download(symbol, start='2014-01-01',\n",
        "                    end=datetime.date.today(), progress=False)\n",
        "    df = df.drop('Adj Close', axis=1)\n",
        "    df = df.dropna()\n",
        "    return df\n",
        "\n",
        "def df_to_X_y(df):\n",
        "  df_as_np = df.to_numpy()\n",
        "  X = []\n",
        "  y = []\n",
        "  date = []\n",
        "  for i in range(len(df_as_np) - 1):\n",
        "    columns_to_get = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "    row = df.loc[df.index[i], columns_to_get]\n",
        "    #print(row)\n",
        "    X.append(row)\n",
        "    y.append(df['Close'][i + 1])\n",
        "    date.append(df.index[i + 1])\n",
        "  return np.array(X), np.array(y), np.array(date)\n",
        "\n",
        "def RNN_model(df,symbol, input_price):\n",
        "\n",
        "    X, y, date = df_to_X_y(df)\n",
        "\n",
        "    # Initialize the scaler\n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    q_80 = int(len(date) * .8)\n",
        "\n",
        "    dates_train, X_train, y_train = date[:q_80], X_scaled[:q_80], y[:q_80]\n",
        "\n",
        "    dates_test, X_test, y_test = date[q_80:], X_scaled[q_80:], y[q_80:]\n",
        "\n",
        "    rnn = Sequential()\n",
        "\n",
        "    rnn.add(SimpleRNN(50, activation='relu',\n",
        "                      input_shape=(X_train.shape[1], 1),))\n",
        "\n",
        "    rnn.add(Dense(1))\n",
        "\n",
        "    rnn.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    rnn.fit(X_train, y_train, epochs=10, batch_size=32,\n",
        "            validation_split=0.2)\n",
        "\n",
        "    preds = rnn.predict(X_test)\n",
        "    score = r2_score(y_test, preds) * 100\n",
        "    st.header('Currency Rate Prediction')\n",
        "    st.write(f'Model Accuracy: {round(score)}%')\n",
        "    get_prediction(rnn, df, input_price)\n",
        "\n",
        "    st.header('Visualize Price Prediction Till Now')\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    plt.plot(dates_test[-100:], preds[-100:])\n",
        "    plt.plot(dates_test[-100:], y_test[-100:])\n",
        "    plt.legend(['Testing Predictions', 'Testing Observations'])\n",
        "    st.pyplot(plt.gcf())\n",
        "\n",
        "def LSTM_model(df, symbol, input_price):\n",
        "    X, y, date = df_to_X_y(df)\n",
        "\n",
        "    # Initialize the scaler\n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    q_80 = int(len(date) * .8)\n",
        "\n",
        "    dates_train, X_train, y_train = date[:q_80], X_scaled[:q_80], y[:q_80]\n",
        "\n",
        "    dates_test, X_test, y_test = date[q_80:], X_scaled[q_80:], y[q_80:]\n",
        "\n",
        "    lstm = Sequential([layers.Input((5, 1)),\n",
        "                    layers.LSTM(64),\n",
        "                    layers.Dense(32, activation='relu'),\n",
        "                    layers.Dense(32, activation='relu'),\n",
        "                    layers.Dense(1)])\n",
        "\n",
        "    lstm.compile(loss='mse',\n",
        "                  optimizer=Adam(learning_rate=0.001, clipvalue=1.0),\n",
        "                  metrics=['mean_absolute_error'])\n",
        "\n",
        "    # Train the model\n",
        "    lstm.fit(X_train, y_train, epochs=10)\n",
        "\n",
        "    preds = lstm.predict(X_test)\n",
        "    score = r2_score(y_test, preds) * 100\n",
        "    st.header('Currency Rate Prediction')\n",
        "    st.write(f'Model Accuracy: {round(score)}%')\n",
        "    get_prediction(lstm, df, input_price)\n",
        "\n",
        "    st.header('Visualization test data')\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    plt.plot(dates_test[-100:], preds[-100:])\n",
        "    plt.plot(dates_test[-100:], y_test[-100:])\n",
        "    plt.legend(['Testing Predictions', 'Testing Observations'])\n",
        "    st.pyplot(plt.gcf())\n",
        "\n",
        "def MLP_model(df, symbol, input_price):\n",
        "    X, y, date = df_to_X_y(df)\n",
        "\n",
        "    # Initialize the scaler\n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    q_80 = int(len(date) * .8)\n",
        "\n",
        "    dates_train, X_train, y_train = date[:q_80], X_scaled[:q_80], y[:q_80]\n",
        "\n",
        "    dates_test, X_test, y_test = date[q_80:], X_scaled[q_80:], y[q_80:]\n",
        "\n",
        "    mlp = Sequential()\n",
        "\n",
        "    mlp.add(Dense(100, activation=\"relu\", input_dim=X_train.shape[1]))\n",
        "    mlp.add(Dense(1, activation=\"relu\"))\n",
        "\n",
        "    mlp.compile(loss='mse', optimizer=\"adam\")\n",
        "\n",
        "    mlp.fit(X_train, y_train, epochs=10 )\n",
        "\n",
        "    preds = mlp.predict(X_test)\n",
        "    score = r2_score(y_test, preds) * 100\n",
        "    st.header('Currency Rate Prediction')\n",
        "    st.write(f'Model Accuracy: {round(score)}%')\n",
        "\n",
        "    get_prediction(mlp,df, input_price)\n",
        "\n",
        "    st.header('Visualization test data')\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    plt.plot(dates_test[-100:], preds[-100:])\n",
        "    plt.plot(dates_test[-100:], y_test[-100:])\n",
        "    plt.legend(['Testing Predictions', 'Testing Observations'])\n",
        "    st.pyplot(plt.gcf())\n",
        "\n",
        "def ANN_model(df, symbol, input_price):\n",
        "    X, y, date = df_to_X_y(df)\n",
        "\n",
        "    # Initialize the scaler\n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    q_80 = int(len(date) * .8)\n",
        "\n",
        "    dates_train, X_train, y_train = date[:q_80], X_scaled[:q_80], y[:q_80]\n",
        "\n",
        "    dates_test, X_test, y_test = date[q_80:], X_scaled[q_80:], y[q_80:]\n",
        "\n",
        "    ann = Sequential()\n",
        "\n",
        "    ann.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))\n",
        "\n",
        "    ann.add(Dense(32, activation='relu'))\n",
        "    ann.add(Dropout(0.2))\n",
        "\n",
        "    ann.add(Dense(1, activation='linear'))\n",
        "\n",
        "    ann.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    ann.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "    preds = ann.predict(X_test)\n",
        "    score = r2_score(y_test, preds) * 100\n",
        "    st.header('Currency Rate Prediction')\n",
        "    st.write(f'Model Accuracy: {round(score)}%')\n",
        "\n",
        "    get_prediction(ann,df, input_price)\n",
        "\n",
        "    st.header('Visualization test data')\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    plt.plot(dates_test[-100:], preds[-100:])\n",
        "    plt.plot(dates_test[-100:], y_test[-100:])\n",
        "    plt.legend(['Testing Predictions', 'Testing Observations'])\n",
        "    st.pyplot(plt.gcf())\n",
        "\n",
        "def GRU_model(df, symbol, input_price):\n",
        "    X, y, date = df_to_X_y(df)\n",
        "\n",
        "    # Initialize the scaler\n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    q_80 = int(len(date) * .8)\n",
        "\n",
        "    dates_train, X_train, y_train = date[:q_80], X_scaled[:q_80], y[:q_80]\n",
        "\n",
        "    dates_test, X_test, y_test = date[q_80:], X_scaled[q_80:], y[q_80:]\n",
        "\n",
        "    regressorGRU = Sequential()\n",
        "\n",
        "    # First GRU layer\n",
        "    regressorGRU.add(GRU(units=100, return_sequences=True,\n",
        "                    input_shape=(X_train.shape[1],1), activation='tanh'))\n",
        "    regressorGRU.add(Dropout(0.3))\n",
        "    # Second GRU layer\n",
        "    regressorGRU.add(GRU(units=80, return_sequences=True,\n",
        "                    input_shape=(X_train.shape[1],1), activation='tanh'))\n",
        "    regressorGRU.add(Dropout(0.2))\n",
        "    # Third GRU layer\n",
        "    regressorGRU.add(GRU(units=50, return_sequences=True,\n",
        "                    input_shape=(X_train.shape[1],1), activation='tanh'))\n",
        "    regressorGRU.add(Dropout(0.1))\n",
        "    # Fourth GRU layer\n",
        "    regressorGRU.add(GRU(units=30, activation='tanh'))\n",
        "    regressorGRU.add(Dropout(0.2))\n",
        "    # The output layer\n",
        "    regressorGRU.add(Dense(units=1))\n",
        "\n",
        "    # Compiling the GRU\n",
        "    regressorGRU.compile(optimizer='adam',loss='mean_squared_error')\n",
        "\n",
        "    # Fitting to the training set\n",
        "    regressorGRU.fit(X_train,y_train,epochs=10,batch_size=150)\n",
        "\n",
        "    preds = regressorGRU.predict(X_test).flatten()\n",
        "    score = r2_score(y_test, preds) * 100\n",
        "    st.header('Currency Rate Prediction')\n",
        "    st.write(f'Model Accuracy: {round(score)}%')\n",
        "    get_prediction(regressorGRU, df, input_price)\n",
        "\n",
        "    st.header('Visualization test data')\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    plt.plot(dates_test[-100:], preds[-100:])\n",
        "    plt.plot(dates_test[-100:], y_test[-100:])\n",
        "    plt.legend(['Testing Predictions', 'Testing Observations'])\n",
        "    st.pyplot(plt.gcf())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOqW6wG8Kj-A",
        "outputId": "7cd27806-7c41-4797-b65d-8e3d596757f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting currency.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile currency.py\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def df_to_X_y(df):\n",
        "  df_as_np = df.to_numpy()\n",
        "  X = []\n",
        "  y = []\n",
        "  date = []\n",
        "  for i in range(len(df_as_np) - 1):\n",
        "    columns_to_get = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "    row = df.loc[df.index[i], columns_to_get]\n",
        "    #print(row)\n",
        "    X.append(row)\n",
        "    y.append(df['Close'][i + 1])\n",
        "    date.append(df.index[i + 1])\n",
        "  return np.array(X), np.array(y), np.array(date)\n",
        "\n",
        "def get_prediction(model, df, input_price):\n",
        "\n",
        "    X, y, date = df_to_X_y(df)\n",
        "\n",
        "    # Initialize the scaler\n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    q_80 = int(len(date) * .8)\n",
        "\n",
        "    dates_train, X_train, y_train = date[:q_80], X_scaled[:q_80], y[:q_80]\n",
        "\n",
        "    dates_test, X_test, y_test = date[q_80:], X_scaled[q_80:], y[q_80:]\n",
        "\n",
        "    preds = model.predict(X_test)\n",
        "\n",
        "    st.write(\"Predicted Price:\", model.predict(input_price)[0, 0])\n",
        "\n",
        "    # Combine the predicted values (y_pred) with the corresponding dates\n",
        "    predictions_df = pd.DataFrame({'Date': dates_test,\n",
        "                                  'Predicted': preds.flatten()})\n",
        "    \"\"\"\n",
        "    # Get the result for the day before the last day\n",
        "    day_before_last_prediction = predictions_df.iloc[-2]\n",
        "    last_day_prediction = predictions_df.iloc[-1]\n",
        "\n",
        "    # Access the date and predicted value for the day before the last day\n",
        "    day_before_last_predicted_date = day_before_last_prediction['Date']\n",
        "    day_before_last_predicted_value = day_before_last_prediction['Predicted']\n",
        "\n",
        "    # Access the date and predicted value for the last day\n",
        "    last_day_predicted_date = last_day_prediction['Date']\n",
        "    last_day_predicted_value = last_day_prediction['Predicted']\n",
        "\n",
        "    st.write(\"Day Before Last Predicted Date:\", day_before_last_predicted_date)\n",
        "    st.write(\"Corresponding Predicted Value (Day Before Last):\",\n",
        "            day_before_last_predicted_value)\n",
        "\n",
        "    st.write(\"\\nLast Day Predicted Date:\", last_day_predicted_date)\n",
        "    st.write(\"Corresponding Predicted Value (Last Day):\",\n",
        "            last_day_predicted_value)\n",
        "\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9RR5_oFKl-Q",
        "outputId": "ee59ed40-5301-4860-f486-903bf1c578cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "from model import predict\n",
        "\n",
        "def main():\n",
        "    st.sidebar.header('Price Predictor App')\n",
        "\n",
        "    predict()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPU3NQYo-KRL",
        "outputId": "369be3aa-c954-4b93-f2da-c24b7ff26d0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25h+ localtunnel@2.0.2\n",
            "updated 1 package and audited 36 packages in 0.884s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found 2 \u001b[93mmoderate\u001b[0m severity vulnerabilities\n",
            "  run `npm audit fix` to fix them, or `npm audit` for details\n",
            "\u001b[K\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q streamlit\n",
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMn48Q4o_EFT"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py &>/content/logs.txt &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PueB1FPz_x3_",
        "outputId": "e5461757-b889-466e-ff29-babfbdf04b32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Password/Enpoint IP for localtunnel is: 34.141.215.27\n"
          ]
        }
      ],
      "source": [
        "import urllib\n",
        "print(\"Password/Enpoint IP for localtunnel is:\",\n",
        "      urllib.request.urlopen('https://ipv4.icanhazip.com')\n",
        "      .read().decode('utf8').strip(\"\\n\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbB7HJeq_G3v",
        "outputId": "563a51d6-5f80-4573-fc39-e440476bef62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 3.419s\n",
            "your url is: https://eleven-glasses-flow.loca.lt\n",
            "/root/.npm/_npx/3861/lib/node_modules/localtunnel/bin/lt.js:81\n",
            "    throw err;\n",
            "    ^\n",
            "\n",
            "Error: connection refused: localtunnel.me:40633 (check your firewall settings)\n",
            "    at Socket.<anonymous> (/root/.npm/_npx/3861/lib/node_modules/\u001b[4mlocaltunnel\u001b[24m/lib/TunnelCluster.js:52:11)\n",
            "\u001b[90m    at Socket.emit (events.js:315:20)\u001b[39m\n",
            "\u001b[90m    at emitErrorNT (internal/streams/destroy.js:106:8)\u001b[39m\n",
            "\u001b[90m    at emitErrorCloseNT (internal/streams/destroy.js:74:3)\u001b[39m\n",
            "\u001b[90m    at processTicksAndRejections (internal/process/task_queues.js:80:21)\u001b[39m\n"
          ]
        }
      ],
      "source": [
        "!npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}